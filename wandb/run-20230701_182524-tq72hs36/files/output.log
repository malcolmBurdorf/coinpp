ModulatedSiren(
  (net): Sequential(
    (0): SirenLayer(
      (linear): Linear(in_features=2, out_features=512, bias=True)
      (activation): Sine()
    )
    (1): SirenLayer(
      (linear): Linear(in_features=512, out_features=512, bias=True)
      (activation): Sine()
    )
    (2): SirenLayer(
      (linear): Linear(in_features=512, out_features=512, bias=True)
      (activation): Sine()
    )
    (3): SirenLayer(
      (linear): Linear(in_features=512, out_features=512, bias=True)
      (activation): Sine()
    )
    (4): SirenLayer(
      (linear): Linear(in_features=512, out_features=512, bias=True)
      (activation): Sine()
    )
    (5): SirenLayer(
      (linear): Linear(in_features=512, out_features=512, bias=True)
      (activation): Sine()
    )
    (6): SirenLayer(
      (linear): Linear(in_features=512, out_features=512, bias=True)
      (activation): Sine()
    )
    (7): SirenLayer(
      (linear): Linear(in_features=512, out_features=512, bias=True)
      (activation): Sine()
    )
    (8): SirenLayer(
      (linear): Linear(in_features=512, out_features=512, bias=True)
      (activation): Sine()
    )
  )
  (last_layer): SirenLayer(
    (linear): Linear(in_features=512, out_features=3, bias=True)
    (activation): Sine()
  )
  (modulation_net): LatentToModulation(
    (net): Linear(in_features=384, out_features=4608, bias=True)
  )
)
Namespace(num_layers=10, dim_hidden=512, w0=50.0, modulate_scale=0, modulate_shift=1, use_latent=1, latent_dim=384, modulation_net_dim_hidden=64, modulation_net_num_layers=1, seed=-1, outer_lr=3e-06, inner_lr=0.01, inner_steps=3, batch_size=64, num_epochs=500, train_dataset='cifar10', test_dataset='cifar10', num_workers=1, gradient_checkpointing=0, num_validation_points=-1, validate_every=2000, validation_inner_steps=[3], patch_shape=[-1], subsample_num_points=-1, do_sampling=1, do_bootstrapping=1, inner_step_boot=3, inner_lr_boot=0.01, data_ratio=0.5, lam=100.0, use_wandb=1, wandb_project_name='cpp_gradncp', wandb_entity='mburdorf', wandb_job_type=None, device=device(type='cpu'))
Epoch 1:
tensor(14.8499, grad_fn=<MulBackward0>)
tensor(0.0669, grad_fn=<MeanBackward0>)
Step 1, Loss 14.917, PSNR 12.394
Traceback (most recent call last):
  File "/content/drive/MyDrive/DLLab/my_coinpp_gradncp/main.py", line 310, in <module>
    main(args)
  File "/content/drive/MyDrive/DLLab/my_coinpp_gradncp/main.py", line 302, in main
    trainer.train_epoch()
  File "/content/drive/MyDrive/DLLab/my_coinpp_gradncp/coinpp/training.py", line 90, in train_epoch
    outputs = metalearning.outer_step(
  File "/content/drive/MyDrive/DLLab/my_coinpp_gradncp/coinpp/metalearning.py", line 223, in outer_step
    modulations, modulations_boot = inner_loop(
  File "/content/drive/MyDrive/DLLab/my_coinpp_gradncp/coinpp/metalearning.py", line 114, in inner_loop
    fitted_modulations_boot = inner_loop_step(
  File "/content/drive/MyDrive/DLLab/my_coinpp_gradncp/coinpp/metalearning.py", line 156, in inner_loop_step
    grad = torch.autograd.grad(
  File "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py", line 303, in grad
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt